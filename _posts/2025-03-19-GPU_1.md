---
permalink: /GPU_1/
title: "GPU Error 정리"
excerpt: "딥러닝 모델 할습에 있어서 빠질 수 없는 GPU의 Error 리스트를 정리해 보았습니다."
layout: single
date: 2025-03-12
categories: [blog]
tags: [Blog]
sidebar_main: true
toc: true
toc_sticky: true
toc_label: 목차
---

## device-side assert triggered error

Machine Unlearning 논문의 코드를 실행하는 도중 발생한 에러입니다.

### ⚠️ 에러 메시지

```shell
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [0,0,0] Assertion t >= 0 && t < n_classes failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [1,0,0] Assertion t >= 0 && t < n_classes failed.
...
RuntimeError: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with TORCH_USE_CUDA_DSA to enable device-side assertions.
```

### ⁉️ 원인 및 해결 방법
위와 같은 에러는 **클래스 인덱스가 1부터 시작할 경우** 발생할 수 있습니다.  
즉, **클래스 인덱스의 범위가 잘못 지정**된 것이 원인입니다.

저는 **Unlearning 알고리즘의 다양한 방법 중** Forget Dataset에 랜덤 레이블을 적용하는 알고리즘을 실행하는 과정에서  
이 오류를 만났습니다.  

결론적으로, 해당 오류는 다음 코드에서 발생했습니다.  

```python
output["labels"][j][i] = np.random.choice(tokenizer.vocab_size)
```

여기서 다음과 같이 `np.random.choice(tokenizer.vocab_size)`를 사용하다 보니,
`tokenizer.vocab_size`보다 큰 값이 생성되는 경우가 있었고,
이로 인해 `Assertion cur_target >= 0 && cur_target < n_classes` 오류가 발생했습니다.

### 🛠 해결 방법

이 문제를 해결하기 위해 **랜덤 레이블을 생성할 때 범위를 명확하게 설정**했습니다.

```python
output["labels"][j][i] = np.random.choice(range(tokenizer.vocab_size))
```

위와 같이 `range()`를 추가함으로써 `tokenizer.vocab_size` 범위 내에서만 랜덤한 값이 선택되도록 수정하였습니다.   
그 결과, 오류가 해결되었습니다.

위와 같은 오류는 대부분 **클래스 인덱스의 범위가 잘못 지정되었을 때 발생**합니다.   
따라서, 오류가 발생하면 **클래스 인덱스가 0이 아닌 1부터 시작하는 것은 아닌지 반드시 확인**해야 합니다.   
일반적으로 **클래스 인덱스는 0부터 시작**해야 하므로, 클래스 라벨의 범위를 점검하는 것이 중요합니다.   