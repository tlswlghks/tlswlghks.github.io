---
permalink: /GPU_1/
title: "GPU Error ì •ë¦¬"
excerpt: "ë”¥ëŸ¬ë‹ ëª¨ë¸ í• ìŠµì— ìˆì–´ì„œ ë¹ ì§ˆ ìˆ˜ ì—†ëŠ” GPUì˜ Error ë¦¬ìŠ¤íŠ¸ë¥¼ ì •ë¦¬í•´ ë³´ì•˜ìŠµë‹ˆë‹¤."
layout: single
date: 2025-03-12
categories: [blog]
tags: [Blog]
sidebar_main: true
toc: true
toc_sticky: true
toc_label: ëª©ì°¨
---

## device-side assert triggered error

Machine Unlearning ë…¼ë¬¸ì˜ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ëŠ” ë„ì¤‘ ë°œìƒí•œ ì—ëŸ¬ì…ë‹ˆë‹¤.

### âš ï¸ ì—ëŸ¬ ë©”ì‹œì§€

```shell
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [0,0,0] Assertion t >= 0 && t < n_classes failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [1,0,0] Assertion t >= 0 && t < n_classes failed.
...
RuntimeError: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with TORCH_USE_CUDA_DSA to enable device-side assertions.
```

### â‰ï¸ ì›ì¸ ë° í•´ê²° ë°©ë²•
ìœ„ì™€ ê°™ì€ ì—ëŸ¬ëŠ” **í´ë˜ìŠ¤ ì¸ë±ìŠ¤ê°€ 1ë¶€í„° ì‹œì‘í•  ê²½ìš°** ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  
ì¦‰, **í´ë˜ìŠ¤ ì¸ë±ìŠ¤ì˜ ë²”ìœ„ê°€ ì˜ëª» ì§€ì •**ëœ ê²ƒì´ ì›ì¸ì…ë‹ˆë‹¤.

ì €ëŠ” **Unlearning ì•Œê³ ë¦¬ì¦˜ì˜ ë‹¤ì–‘í•œ ë°©ë²• ì¤‘** Forget Datasetì— ëœë¤ ë ˆì´ë¸”ì„ ì ìš©í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ì„ ì‹¤í–‰í•˜ëŠ” ê³¼ì •ì—ì„œ  
ì´ ì˜¤ë¥˜ë¥¼ ë§Œë‚¬ìŠµë‹ˆë‹¤.  

ê²°ë¡ ì ìœ¼ë¡œ, í•´ë‹¹ ì˜¤ë¥˜ëŠ” ë‹¤ìŒ ì½”ë“œì—ì„œ ë°œìƒí–ˆìŠµë‹ˆë‹¤.  

```python
output["labels"][j][i] = np.random.choice(tokenizer.vocab_size)
```

ì—¬ê¸°ì„œ ë‹¤ìŒê³¼ ê°™ì´ `np.random.choice(tokenizer.vocab_size)`ë¥¼ ì‚¬ìš©í•˜ë‹¤ ë³´ë‹ˆ,
`tokenizer.vocab_size`ë³´ë‹¤ í° ê°’ì´ ìƒì„±ë˜ëŠ” ê²½ìš°ê°€ ìˆì—ˆê³ ,
ì´ë¡œ ì¸í•´ `Assertion cur_target >= 0 && cur_target < n_classes` ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.

### ğŸ›  í•´ê²° ë°©ë²•

ì´ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ **ëœë¤ ë ˆì´ë¸”ì„ ìƒì„±í•  ë•Œ ë²”ìœ„ë¥¼ ëª…í™•í•˜ê²Œ ì„¤ì •**í–ˆìŠµë‹ˆë‹¤.

```python
output["labels"][j][i] = np.random.choice(range(tokenizer.vocab_size))
```

ìœ„ì™€ ê°™ì´ `range()`ë¥¼ ì¶”ê°€í•¨ìœ¼ë¡œì¨ `tokenizer.vocab_size` ë²”ìœ„ ë‚´ì—ì„œë§Œ ëœë¤í•œ ê°’ì´ ì„ íƒë˜ë„ë¡ ìˆ˜ì •í•˜ì˜€ìŠµë‹ˆë‹¤.   
ê·¸ ê²°ê³¼, ì˜¤ë¥˜ê°€ í•´ê²°ë˜ì—ˆìŠµë‹ˆë‹¤.

ìœ„ì™€ ê°™ì€ ì˜¤ë¥˜ëŠ” ëŒ€ë¶€ë¶„ **í´ë˜ìŠ¤ ì¸ë±ìŠ¤ì˜ ë²”ìœ„ê°€ ì˜ëª» ì§€ì •ë˜ì—ˆì„ ë•Œ ë°œìƒ**í•©ë‹ˆë‹¤.   
ë”°ë¼ì„œ, ì˜¤ë¥˜ê°€ ë°œìƒí•˜ë©´ **í´ë˜ìŠ¤ ì¸ë±ìŠ¤ê°€ 0ì´ ì•„ë‹Œ 1ë¶€í„° ì‹œì‘í•˜ëŠ” ê²ƒì€ ì•„ë‹Œì§€ ë°˜ë“œì‹œ í™•ì¸**í•´ì•¼ í•©ë‹ˆë‹¤.   
ì¼ë°˜ì ìœ¼ë¡œ **í´ë˜ìŠ¤ ì¸ë±ìŠ¤ëŠ” 0ë¶€í„° ì‹œì‘**í•´ì•¼ í•˜ë¯€ë¡œ, í´ë˜ìŠ¤ ë¼ë²¨ì˜ ë²”ìœ„ë¥¼ ì ê²€í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.   