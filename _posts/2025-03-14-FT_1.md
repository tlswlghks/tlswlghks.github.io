---
permalink: /TR/
title: "Gemma-2-2b-it Fine-Tuning Report"
layout: single
date: 2025-03-14
categories: [blog]
tags: [Blog]
sidebar_main: true
toc: false
toc_sticky: false
toc_label: ""
---

<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

# Gemma-2-2b-it Fine-Tuning Report

**Gemma**는 오픈 소스 모델로, 엣지 디바이스에서 실행 가능한 **소형 LLM**입니다. 
Gemma는 **text-to-text 방식의 decoder-only LLM 모델**로 영어로 제공되며, **질문 답변(question answering), 요약(summarization), 추론(reasoning)과 같은 텍스트 생성(text generation) 작업**에 적합합니다.

본 게시글에서는 **Gemma-2-2b-it 모델을 기반으로 QLoRA Fine-tuning을 진행한 과정과 결과**를 정리합니다.

---

## Datasets

Fine-tuning을 위해 **KorMedMCQA**와 **Hidoc** 데이터를 사용하였습니다.

### KorMedMCQA

KorMedMCQA는 2012년부터 2024년까지 한국에서 실시된 **전문 의료 면허 시험**에서 파생된 최초의 한국어 의료 객관식 QA 벤치마크 데이터셋입니다. **의사(doctor), 간호사(nurse), 치과의사(dentist), 약사(pharm) 시험에서 출제된 문제**가 포함되어 있습니다.

- 전체 데이터 개수: **7,469개**
- Train set: **3,401개**
- Validation set: **1,059개**
- Test set: **3,009개**

KorMedMCQA는 **질문(question)과 객관식 답변(A-E)**을 합쳐 Question을 구성했으며, Instruction은 **"질문을 보고, 제시된 [A-E] 중 정답을 맞추세요."**로 통일하였습니다.

#### 데이터 구조 예시
```json
{
  "question": "65세 여자가 혀의 통증으로 내원하였다. 혈액검사 결과 혈색소 수치가 10.5 g/dL이고, 평균적혈구용적(mean corpuscular volume, MCV)이 증가하였다. 진단을 위한 추가적인 검사 항목은?\nA. 항핵항체(ANA)\nB. 류마티스인자(RF)\nC. 비타민B12(cobalamin)\nD. 갑상샘자극호르몬(TSH)\nE. 알칼리인산분해효소(ALP)\n정답:",
  "instruction": "질문을 보고, 제시된 [A-E] 중 정답을 맞추세요.",
  "answer": "C"
}
```

### Hidoc

Hidoc 데이터셋은 **건강포털 하이닥(HiDoc) 홈페이지의 건강 상담 데이터**를 크롤링하여 구축하였습니다. 
총 **373개의 질문 데이터**를 확보하였으며, 일부 질문이 명확하지 않아 **aya-expanse-32b 모델을 활용하여 질문을 정리하고, 추가 정보를 별도로 분리하여 Instruction을 구성**하였습니다.

#### 데이터 구조 예시
```json
{
  "question": "건강검진 결과에 대한 종합적인 소견과 향후 조치에 대한 구체적인 조언을 구합니다.",
  "instruction": "다음은 환자 정보와 질문입니다. 환자 정보를 참고하여 질문에 답변해주세요.\n\n1차 건강검진 결과: AST 114, ALT 117, r-GTP 57, 공복혈당 133\n2차 건강검진 결과: AST 193, ALT 174, r-GTP 64\n복부 초음파 소견: 중증도 지방간, 비장 종대(13cm)\n당화혈색소 수치: 6.4\n기본 정보: 35세 여성, 5세 자녀의 기혼녀, 비흡연, 음주는 월 1~3회, 어머니는 간 종양 수술 이력, 바쁜 업무 환경(주 5일 야근, 월 1~2회 밤샘 작업)",
  "answer": "제공해주신 건강검진 결과를 종합적으로 살펴보면, 간 기능 수치와 지방간 소견이 주목할 만합니다. 추가적인 검사와 치료 계획은 전문의와 상의하여 결정하는 것이 좋습니다."
}
```

#### EDA 분석 결과
Hidoc 데이터셋의 길이를 기준으로 간단한 EDA를 진행한 결과는 다음과 같습니다.

- **최소 길이:** 577개
- **중간 길이:** 1,098개
- **최대 길이:** 2,108개

최종적으로 **KorMedMCQA와 Hidoc 데이터셋을 결합하여 Instruction 데이터셋을 구축**하였습니다.

---

## Fine-Tuning 과정

이렇게 구축된 **Instruction 데이터셋**을 이용하여 **Gemma-2-2b-it 모델의 QLoRA Fine-Tuning**을 진행하였습니다.

모델의 성능 평가는 **Eleuther.ai에서 개발한 자동 평가 프레임워크인 lm-eval-harness**를 활용하였습니다. 
lm-eval-harness를 사용하면 다양한 벤치마크 데이터셋을 활용하여 LLM의 성능을 자동으로 평가할 수 있습니다.

Fine-Tuning 성능 평가는 **KorMedMCQA 벤치마크 데이터셋**을 이용하여 진행하였습니다. 
단순한 QLoRA Fine-Tuning 실험이었기에 해당 벤치마크를 사용하였지만, 향후 Fine-Tuning 시에는 **Decontamination(데이터 중복 제거)을 철저히 수행**할 계획입니다.

### KorMedMCQA Benchmark 평가 결과

| Dataset  | Base Model | Fine-Tuned Model |
|----------|-----------|-----------------|
| Doctor (435)  | 33.1%  | **38.39%** (▴ 15.98%) |
| Nurse (878)   | 48.86% | **51.03%** (▴ 4.44%)  |
| Dentist (811) | 35.64% | **37.85%** (▴ 6.2%)   |
| Pharm (885)   | 42.49% | **43.05%** (▴ 1.32%)  |

위 결과를 통해 **Pre-trained 모델 대비 성능 향상**이 있음을 확인하였습니다.

---

## 결론 및 향후 계획

이번 Fine-Tuning 과정에서 데이터셋 구축에 아쉬운 점이 있었지만, 결과적으로 **일정 수준의 성능 향상을 확인**할 수 있었습니다.

향후에는 **Decontamination을 철저히 수행**하고, **데이터 전처리 과정을 더욱 강화**하여 데이터의 퀄리티를 높일 계획입니다. 또한, Fine-Tuning 이후 **RLHF(Reinforcement Learning from Human Feedback)를 추가하여 사용자 선호도를 반영한 모델**로 발전시킬 예정입니다.